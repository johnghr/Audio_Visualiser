[{"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/index.js":"1","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/App.js":"2","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/reportWebVitals.js":"3","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/tracks.js":"4","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Analysers/AudioAnalyser.js":"5","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/AudioPlayer.jsx":"6","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/AudioControls.jsx":"7","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Visualisers/FrequencyVisualiser.js":"8","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Visualisers/WaveformVisualiser.js":"9","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/containers/MediaPlayer.jsx":"10","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/TrackForm/UploadForm.jsx":"11"},{"size":500,"mtime":1625517263308,"results":"12","hashOfConfig":"13"},{"size":594,"mtime":1625573767551,"results":"14","hashOfConfig":"13"},{"size":362,"mtime":1625517263319,"results":"15","hashOfConfig":"13"},{"size":708,"mtime":1625517263241,"results":"16","hashOfConfig":"13"},{"size":3282,"mtime":1625520126071,"results":"17","hashOfConfig":"13"},{"size":5171,"mtime":1625520831800,"results":"18","hashOfConfig":"13"},{"size":1912,"mtime":1625517263240,"results":"19","hashOfConfig":"13"},{"size":1963,"mtime":1625518971554,"results":"20","hashOfConfig":"13"},{"size":2370,"mtime":1625560438336,"results":"21","hashOfConfig":"13"},{"size":2547,"mtime":1625517263308,"results":"22","hashOfConfig":"13"},{"size":821,"mtime":1625520276203,"results":"23","hashOfConfig":"13"},{"filePath":"24","messages":"25","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},"kxb1hw",{"filePath":"27","messages":"28","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"29"},{"filePath":"30","messages":"31","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"32","messages":"33","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"34","messages":"35","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"36","usedDeprecatedRules":"26"},{"filePath":"37","messages":"38","errorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"39","usedDeprecatedRules":"26"},{"filePath":"40","messages":"41","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"42","messages":"43","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"44","usedDeprecatedRules":"26"},{"filePath":"45","messages":"46","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"47","usedDeprecatedRules":"26"},{"filePath":"48","messages":"49","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"26"},{"filePath":"50","messages":"51","errorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":"52","usedDeprecatedRules":"26"},"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/index.js",[],["53","54"],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/App.js",["55"],"import MediaPlayer from './containers/MediaPlayer';\nimport React, {useEffect, useState} from 'react';\nimport './App.css';\n// import { getUploads } from './services/TrackService';\nimport UploadForm from './components/TrackForm/UploadForm'\nconst baseUrl = 'http://localhost:5000/';\n\nfunction App() {\n\n\n  const [tracks, setTracks] = useState([])\n\n  useEffect(() => {\n    \n    fetch(baseUrl)\n        .then(data => setTracks(data))\n        console.log(tracks)\n  }, [])\n  \n\n  return (\n    <div>\n      <MediaPlayer></MediaPlayer>\n      <UploadForm></UploadForm>\n    </div>\n  );\n}\n\nexport default App;\n","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/reportWebVitals.js",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/tracks.js",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Analysers/AudioAnalyser.js",["56"],"import React, {useEffect, useState, useRef} from 'react';\nimport ExperimentalVisualiser from '../Visualisers/WaveformVisualiser';\nimport FrequencyVisualiser from '../Visualisers/FrequencyVisualiser';\n\nconst AudioAnalyser = ({ mode, input, visualiserType, background }) => {\n\n    const [audioData, setAudioData] = useState(new Uint8Array(0));\n    \n    // creates an audio context and stores it in ref    \n    const audioContextRef = useRef(new (window.AudioContext || window.webkitAudioContext)());\n    // sets audioContext to be the current ref of audioContext \n    const audioContext = audioContextRef.current;\n    \n    const sourceRef = useRef(null);\n    let source = sourceRef.current;\n    const analyserRef = useRef(audioContext.createAnalyser())\n    const analyser = analyserRef.current;\n    const [analyserDisconnected, setAnalyserDisconnected] = useState(false)\n    \n\n\n    useEffect( () => {\n        console.log('analyser input', input)\n        // empty request animation frame Id\n        let rafId; \n         \n        // Creates a data Array which is half the length of the fftSize;\n        // it takes in unsigned integers  \n        const dataArray = new Uint8Array(analyser.frequencyBinCount);\n        // connects the audio stream to the analyser node using the relevant method depending on input\n        if(mode === \"track\"){\n                    source = audioContext.createMediaElementSource(input);\n                    source.connect(analyser).connect(audioContext.destination);\n                } else {\n                    source = audioContext.createMediaStreamSource(input);\n                    source.connect(analyser);\n                }\n        \n        \n        const tick = () => {\n            // copies wave form data into the dataArray which is passed in as an argument   \n            analyser.getByteTimeDomainData(dataArray)\n            // sets audioData to be the value of a copy of dataArray\n            setAudioData([...dataArray])\n            // requests a re-render while calling tick in a recursive loop\n            rafId = requestAnimationFrame(tick);\n        }\n    \n        rafId = requestAnimationFrame(tick);\n\n        return function cleanup() {\n            console.log(\"disconnect analyser\")\n            if(mode === \"track\"){\n                console.log(\"mode is track\")\n                source.disconnect(analyser);\n                setAnalyserDisconnected(true)\n            } else {\n                console.log(\"mode is not track\")\n                source.disconnect()\n            }\n            cancelAnimationFrame(rafId);\n            console.log('clean up on aisle 3')   \n        }\n\n    }, [mode, input])\n\n    return(\n        <div>\n            {visualiserType === \"Waveform\" ? \n            <ExperimentalVisualiser \n                audioData={audioData} \n                analyserDisconnected={analyserDisconnected} \n                setAnalyserDisconnected={setAnalyserDisconnected}\n                background={background}\n            /> :\n            <FrequencyVisualiser \n                audioData={audioData} \n                analyser={analyser}\n                setAnalyserDisconnected={setAnalyserDisconnected}\n                background={background}\n            /> \n            }\n        </div>\n        \n    )\n\n}\n\nexport default AudioAnalyser;","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/AudioPlayer.jsx",["57","58"],"import React, {useState, useEffect, useRef} from 'react';\nimport AudioControls from './AudioControls.jsx';\n\nconst AudioPlayer = ({ tracks, onChangeTrack, onPauseTrack }) => {\n\n    // index of track being played\n    const [trackIndex, setTrackIndex] = useState(0);\n    // current progress of track being played\n    const [trackProgress, setTrackProgress] = useState(0);\n    // wether or not track is being played\n    const [isPlaying, setIsPlaying] = useState(false);\n    // current title and source equal the current track index\n    const {title, audioSrc} = tracks[trackIndex];\n    \n    // stores Audio element plus audio source in a ref\n    const audioRef = useRef(new Audio(audioSrc));\n    \n    const intervalRef = useRef();\n    const isReady = useRef(false);\n\n    const { duration } = audioRef.current;\n    // const currentPercentage = duration ? `${(trackProgress / duration) * 100}%` : '0%';\n    // const trackStyling = `-webkit-gradient(linear, 0% 0%, 100% 0%, color-stop(${currentPercentage}, #fff), color-stop(${currentPercentage}, #777))`;\n\n    // PREV -  handles previous track click\n    const toPrevTrack = () => {\n        // if trackIndex minus 1 is less than zero, set track index to the last track\n        if (trackIndex - 1 < 0){\n            setTrackIndex(tracks.length - 1);\n        } else {\n            setTrackIndex(trackIndex - 1);\n        }\n    }\n    \n    // NEXT - handles next track click\n    const toNextTrack = () => {\n        // if trackIndex is less than tracks length go to next track, otherwise go to first track\n        if (trackIndex < tracks.length -1){\n            setTrackIndex(trackIndex + 1);\n        } else {\n            setTrackIndex(0);\n        }\n    }\n    \n    // PLAY\n    useEffect(() => {\n        // when isPlaying changes:\n        // if isPlaying is true, play the track in audio tag \n        if(isPlaying) {\n            // update track for analyser\n            \n            audioRef.current.play();\n            // console.log('setting track')\n            onChangeTrack(audioRef.current)\n            startTimer();\n        } else {\n            // otherwise clear the intervalRef and pause the track in audio tag\n            console.log('pause track')\n            clearInterval(intervalRef.current)\n            audioRef.current.pause();\n            // onPauseTrack();\n        }\n    },[isPlaying])\n\n    useEffect(() => {\n        // pause and clean up on unmount / clear any setInterval timers\n\n        return () => {\n            audioRef.current.pause();\n            clearInterval(intervalRef.current);\n        }\n\n    }, [])\n\n    // NEXT track\n    useEffect(() => {\n        \n        // runs when trackIndex is updated, allowing current track to be paused while\n        // updating the value of audioRef to new source, resetting the progress state and \n        // setting new track to play\n\n        audioRef.current.pause()\n        audioRef.current = new Audio(audioSrc);\n        setTrackProgress(audioRef.current.currentTime);\n\n        if (isReady.current) {\n            audioRef.current.play();\n            setIsPlaying(true);\n            startTimer()\n        } else {\n            isReady.current = true;\n        }\n    }, [trackIndex])\n\n    const startTimer = () => {\n        // clear any timers already running\n        clearInterval(intervalRef.current);\n\n        // check track every second, if ended reset the player, otherwise update track progress\n        intervalRef.current = setInterval(() => {\n            if (audioRef.current.ended) {\n                setTrackProgress(0);\n                setIsPlaying(false);\n                console.log(\"player reset:\", audioRef.current)\n            } else {\n                setTrackProgress(audioRef.current.currentTime);\n            }\n        }, [1000])\n    }\n\n\n    const onScrub = (value) => {\n        // clear any timers already running\n        clearInterval(intervalRef.current);\n        audioRef.current.currentTime = value;\n        setTrackProgress(audioRef.current.currentTime);\n    }\n\n    const onScrubEnd = () => {\n        // if isPlayings value is false then set it to true\n        if (!isPlaying) {\n            setIsPlaying(true);\n        }\n        startTimer();\n    }   \n\n    return(\n        \n        <div className=\"audio-player\">\n            <div className=\"track-info\">\n                <h3 className=\"title\">{title}</h3>\n                <AudioControls\n                    isPlaying={isPlaying}\n                    onPrevClick={toPrevTrack}\n                    onNextClick={toNextTrack}\n                    onPlayPauseClick={setIsPlaying}\n                    // onPlay={toggleTrack}\n                />\n                <input \n                    type=\"range\"\n                    value={trackProgress}\n                    step=\"1\"\n                    min=\"0\"\n                    max={duration ? duration : `${duration}`}\n                    className=\"progress\"\n                    onChange={(e) => onScrub(e.target.value)}\n                    onMouseUp={onScrubEnd}\n                    onKeyUp={onScrubEnd}\n                    // style={{ background: trackStyling}}\n                />\n            </div>\n        </div>\n\n    ) \n            \n\n}\n\nexport default AudioPlayer;","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/AudioControls.jsx",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Visualisers/FrequencyVisualiser.js",["59"],"import React, { useRef, useEffect } from 'react';\n\n//let testWaveFormRef = useRef(Array.from({length: 1024}, () => Math.floor(Math.random() * 255)));\n//  const testWaveForm = testWaveFormRef.current;\n\nconst FrequencyVisualiser = ({ audioData, analyser, background }) => {\n\n    const canvasRef = useRef();\n\n    useEffect(() => {\n        \n        let canvas = canvasRef.current;\n        let height = canvas.height;\n        let width = canvas.width;\n        let context = canvas.getContext('2d');\n        let randomColour = \"#\" + ((1 << 24) * Math.random() | 0).toString(16)\n\n        // a quarter of the fft size default\n        analyser.fftSize = 256;\n        console.log(analyser)\n        //bufferLength equals half the fftSize i.e. 128\n        let bufferLength = analyser.frequencyBinCount;\n        console.log(\"buffer length\", bufferLength);\n        // let dataArray = new Uint8Array(bufferLength);\n\n        context.clearRect(0, 0, width, height);\n\n        const render = () => {\n            if(background === \"Clear\"){\n                context.fillStyle = '#00aeb0';   \n            } else {\n                context.fillStyle = '#000000'\n            }\n            \n            context.fillRect(0, 0, width, height);\n\n            let barWidth = (width / bufferLength) * 2.5;\n            let barHeight;\n            let x = 0;\n\n            for (var i = 0; i < bufferLength; i++) {\n                // the height of a bar equals the current audio sample value halved\n                barHeight = audioData[i] / 0.3;\n                \n                context.fillStyle = randomColour;\n                context.fillRect(x, height - barHeight / 2, barWidth, barHeight)\n\n                x += barWidth + 1;\n            }\n        };\n\n        render()\n\n    }, [audioData]);\n\n    return (\n        <canvas\n            className=\"frequency-canvas\"\n            width=\"550\"\n            height=\"550\"\n            ref={canvasRef}\n        />\n    )\n\n}\n\nexport default FrequencyVisualiser;","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Visualisers/WaveformVisualiser.js",["60"],"import React, {useRef, useEffect} from 'react';\n\n//let testWaveFormRef = useRef(Array.from({length: 1024}, () => Math.floor(Math.random() * 255)));\n//  const testWaveForm = testWaveFormRef.current;\n\nconst WaveformVisualiser = ({\n    audioData, \n    setAnalyserDisconnected, \n    analyserDisconnected,\n    background\n}) => {\n\n    const canvasRef = useRef();\n    \n\n    //clear the canvas every 30 seconds\n    // useEffect(() => {\n        \n    //     const clearCanvas = () => {\n    //         context.clearRect(0, 0, width, height);\n    //     }\n    //     setInterval(clearCanvas, 30000)\n\n    // },[])\n\n    useEffect(() => {\n        \n        let canvas = canvasRef.current;\n        let height = canvas.height;\n        let width = canvas.width;\n        let context = canvas.getContext('2d');\n        let x = 0;\n        let sliceWidth = width / audioData.length;\n        let randomColour = \"#\" + ((1<<24)*Math.random() | 0).toString(16)\n        if(background === \"Black\"){\n            context.fillRect(0, 0, width, height)\n        } else {\n            context.fillStyle = '#000000'\n        }\n        \n        // if the analyser has been disconnected clear the canvas and reset analyserDisconnected to false\n        if(analyserDisconnected){\n            context.clearRect(0, 0, width, height);\n            setAnalyserDisconnected(false)\n        }\n        \n        const renderWaveform = () => {\n            \n            if(background === \"Black\"){\n                context.fillRect(0, 0,width, height)\n            } else {\n                context.fillStyle = '#000000'\n            }\n            \n            context.lineWidth = 2;\n            context.strokeStyle = randomColour;\n            \n            context.beginPath();\n            context.moveTo(0, height / 2);\n\n            for(const item of audioData) {\n                const y = (item / 255.0) * height;\n                context.lineTo(x, y);\n                x += sliceWidth;\n            }\n            // console.log(\"Audio-data:\", audioData)\n            context.lineTo(x, height / 2);\n            context.stroke();\n            \n        }\n        \n        renderWaveform()\n        \n       \n    }, [audioData, background])\n\n    return(\n        <canvas \n            className=\"canvas\"\n            width=\"550\" \n            height=\"550\" \n            ref={canvasRef}\n        />\n    )\n\n}\n\nexport default WaveformVisualiser;","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/containers/MediaPlayer.jsx",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/TrackForm/UploadForm.jsx",["61","62"],"import React, {useState, useEffect} from 'react';\nconst baseUrl = 'http://localhost:5000/upload';\n\nconst UploadForm = () => {\n    const onSubmit = e => {\n        e.preventDefault();\n        const formData = new FormData(e.currentTarget);\n        const config = {\n            method: 'POST',\n            // body not data\n            body: formData,\n        }\n            \n        fetch(baseUrl, config)\n            .then((res) => res.json())\n            .then(data => console.log(data))\n            .catch((err) => (console.log(\"error\",err)));\n    }\n\n    return(\n        <div>\n           <form onSubmit={onSubmit} encType=\"multipart/form-data\">\n                <input type=\"file\" name=\"track\" />\n                <input type=\"submit\" value=\"Upload\"/>\n            </form> \n        </div>\n    )\n\n}\n\nexport default UploadForm;",{"ruleId":"63","replacedBy":"64"},{"ruleId":"65","replacedBy":"66"},{"ruleId":"67","severity":1,"message":"68","line":18,"column":6,"nodeType":"69","endLine":18,"endColumn":8,"suggestions":"70"},{"ruleId":"67","severity":1,"message":"71","line":32,"column":30,"nodeType":"72","endLine":32,"endColumn":74},{"ruleId":"67","severity":1,"message":"73","line":63,"column":7,"nodeType":"69","endLine":63,"endColumn":18,"suggestions":"74"},{"ruleId":"67","severity":1,"message":"75","line":93,"column":8,"nodeType":"69","endLine":93,"endColumn":20,"suggestions":"76"},{"ruleId":"67","severity":1,"message":"77","line":54,"column":8,"nodeType":"69","endLine":54,"endColumn":19,"suggestions":"78"},{"ruleId":"67","severity":1,"message":"79","line":75,"column":8,"nodeType":"69","endLine":75,"endColumn":31,"suggestions":"80"},{"ruleId":"81","severity":1,"message":"82","line":1,"column":16,"nodeType":"83","messageId":"84","endLine":1,"endColumn":24},{"ruleId":"81","severity":1,"message":"85","line":1,"column":26,"nodeType":"83","messageId":"84","endLine":1,"endColumn":35},"no-native-reassign",["86"],"no-negated-in-lhs",["87"],"react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'tracks'. Either include it or remove the dependency array.","ArrayExpression",["88"],"Assignments to the 'source' variable from inside React Hook useEffect will be lost after each render. To preserve the value over time, store it in a useRef Hook and keep the mutable value in the '.current' property. Otherwise, you can move this variable directly inside useEffect.","CallExpression","React Hook useEffect has a missing dependency: 'onChangeTrack'. Either include it or remove the dependency array. If 'onChangeTrack' changes too often, find the parent component that defines it and wrap that definition in useCallback.",["89"],"React Hook useEffect has a missing dependency: 'audioSrc'. Either include it or remove the dependency array.",["90"],"React Hook useEffect has missing dependencies: 'analyser' and 'background'. Either include them or remove the dependency array.",["91"],"React Hook useEffect has missing dependencies: 'analyserDisconnected' and 'setAnalyserDisconnected'. Either include them or remove the dependency array. If 'setAnalyserDisconnected' changes too often, find the parent component that defines it and wrap that definition in useCallback.",["92"],"no-unused-vars","'useState' is defined but never used.","Identifier","unusedVar","'useEffect' is defined but never used.","no-global-assign","no-unsafe-negation",{"desc":"93","fix":"94"},{"desc":"95","fix":"96"},{"desc":"97","fix":"98"},{"desc":"99","fix":"100"},{"desc":"101","fix":"102"},"Update the dependencies array to be: [tracks]",{"range":"103","text":"104"},"Update the dependencies array to be: [isPlaying, onChangeTrack]",{"range":"105","text":"106"},"Update the dependencies array to be: [audioSrc, trackIndex]",{"range":"107","text":"108"},"Update the dependencies array to be: [analyser, audioData, background]",{"range":"109","text":"110"},"Update the dependencies array to be: [analyserDisconnected, audioData, background, setAnalyserDisconnected]",{"range":"111","text":"112"},[460,462],"[tracks]",[2325,2336],"[isPlaying, onChangeTrack]",[3163,3175],"[audioSrc, trackIndex]",[1745,1756],"[analyser, audioData, background]",[2150,2173],"[analyserDisconnected, audioData, background, setAnalyserDisconnected]"]