[{"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/index.js":"1","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/App.js":"2","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/reportWebVitals.js":"3","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/tracks.js":"4","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Analysers/AudioAnalyser.js":"5","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/AudioPlayer.jsx":"6","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/AudioControls.jsx":"7","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Visualisers/FrequencyVisualiser.js":"8","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Visualisers/WaveformVisualiser.js":"9","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/containers/MediaPlayer.jsx":"10","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/TrackForm/UploadForm.jsx":"11","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/services/TrackService.js":"12"},{"size":500,"mtime":1624800491770,"results":"13","hashOfConfig":"14"},{"size":917,"mtime":1625487362855,"results":"15","hashOfConfig":"14"},{"size":362,"mtime":1624800491772,"results":"16","hashOfConfig":"14"},{"size":708,"mtime":1625240271247,"results":"17","hashOfConfig":"14"},{"size":3274,"mtime":1625487451029,"results":"18","hashOfConfig":"14"},{"size":5186,"mtime":1625507127643,"results":"19","hashOfConfig":"14"},{"size":1912,"mtime":1625240131027,"results":"20","hashOfConfig":"14"},{"size":1955,"mtime":1625488543148,"results":"21","hashOfConfig":"14"},{"size":2353,"mtime":1625488975092,"results":"22","hashOfConfig":"14"},{"size":2547,"mtime":1625487832164,"results":"23","hashOfConfig":"14"},{"size":899,"mtime":1625515224215,"results":"24","hashOfConfig":"14"},{"size":403,"mtime":1625487333173,"results":"25","hashOfConfig":"14"},{"filePath":"26","messages":"27","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"28"},"kxb1hw",{"filePath":"29","messages":"30","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"28"},{"filePath":"31","messages":"32","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"28"},{"filePath":"33","messages":"34","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"28"},{"filePath":"35","messages":"36","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"37","usedDeprecatedRules":"28"},{"filePath":"38","messages":"39","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"40","usedDeprecatedRules":"28"},{"filePath":"41","messages":"42","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"28"},{"filePath":"43","messages":"44","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"45","usedDeprecatedRules":"28"},{"filePath":"46","messages":"47","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"48","usedDeprecatedRules":"28"},{"filePath":"49","messages":"50","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"28"},{"filePath":"51","messages":"52","errorCount":0,"warningCount":2,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"53","messages":"54","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/index.js",[],["55","56"],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/App.js",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/reportWebVitals.js",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/tracks.js",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Analysers/AudioAnalyser.js",["57"],"import React, {useEffect, useState, useRef} from 'react';\nimport WaveformVisualiser from '../Visualisers/WaveformVisualiser';\nimport FrequencyVisualiser from '../Visualisers/FrequencyVisualiser';\n\nconst AudioAnalyser = ({ mode, input, visualiserType, background }) => {\n\n    const [audioData, setAudioData] = useState(new Uint8Array(0));\n    \n    // creates an audio context and stores it in ref    \n    const audioContextRef = useRef(new (window.AudioContext || window.webkitAudioContext)());\n    // sets audioContext to be the current ref of audioContext \n    const audioContext = audioContextRef.current;\n    \n    const sourceRef = useRef(null);\n    let source = sourceRef.current;\n    const analyserRef = useRef(audioContext.createAnalyser())\n    const analyser = analyserRef.current;\n    const [analyserDisconnected, setAnalyserDisconnected] = useState(false)\n    \n\n\n    useEffect( () => {\n        console.log('analyser input', input)\n        // empty request animation frame Id\n        let rafId; \n         \n        // Creates a data Array which is half the length of the fftSize;\n        // it takes in unsigned integers  \n        const dataArray = new Uint8Array(analyser.frequencyBinCount);\n        // connects the audio stream to the analyser node using the relevant method depending on input\n        if(mode === \"track\"){\n                    source = audioContext.createMediaElementSource(input);\n                    source.connect(analyser).connect(audioContext.destination);\n                } else {\n                    source = audioContext.createMediaStreamSource(input);\n                    source.connect(analyser);\n                }\n        \n        \n        const tick = () => {\n            // copies wave form data into the dataArray which is passed in as an argument   \n            analyser.getByteTimeDomainData(dataArray)\n            // sets audioData to be the value of a copy of dataArray\n            setAudioData([...dataArray])\n            // requests a re-render while calling tick in a recursive loop\n            rafId = requestAnimationFrame(tick);\n        }\n    \n        rafId = requestAnimationFrame(tick);\n\n        return function cleanup() {\n            console.log(\"disconnect analyser\")\n            if(mode === \"track\"){\n                console.log(\"mode is track\")\n                source.disconnect(analyser);\n                setAnalyserDisconnected(true)\n            } else {\n                console.log(\"mode is not track\")\n                source.disconnect()\n            }\n            cancelAnimationFrame(rafId);\n            console.log('clean up on aisle 3')   \n        }\n\n    }, [mode, input])\n\n    return(\n        <div>\n            {visualiserType === \"Waveform\" ? \n            <WaveformVisualiser \n                audioData={audioData} \n                analyserDisconnected={analyserDisconnected} \n                setAnalyserDisconnected={setAnalyserDisconnected}\n                background={background}\n            /> :\n            <FrequencyVisualiser \n                audioData={audioData} \n                analyser={analyser}\n                setAnalyserDisconnected={setAnalyserDisconnected}\n                background={background}\n            /> \n            }\n        </div>\n        \n    )\n\n}\n\nexport default AudioAnalyser;","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/AudioPlayer.jsx",["58"],"import React, {useState, useEffect, useRef} from 'react';\nimport AudioControls from './AudioControls.jsx';\n\nconst AudioPlayer = ({ tracks, onChangeTrack, onPauseTrack }) => {\n\n    // index of track being played\n    const [trackIndex, setTrackIndex] = useState(0);\n    // current progress of track being played\n    const [trackProgress, setTrackProgress] = useState(0);\n    // wether or not track is being played\n    const [isPlaying, setIsPlaying] = useState(false);\n    // current title and source equal the current track index\n    const {title, audioSrc} = tracks[trackIndex];\n    \n    // stores Audio element plus audio source in a ref\n    const audioRef = useRef(new Audio(audioSrc));\n    \n    const intervalRef = useRef();\n    const isReady = useRef(false);\n\n    const { duration } = audioRef.current;\n    // const currentPercentage = duration ? `${(trackProgress / duration) * 100}%` : '0%';\n    // const trackStyling = `-webkit-gradient(linear, 0% 0%, 100% 0%, color-stop(${currentPercentage}, #fff), color-stop(${currentPercentage}, #777))`;\n\n    // PREV -  handles previous track click\n    const toPrevTrack = () => {\n        // if trackIndex minus 1 is less than zero, set track index to the last track\n        if (trackIndex - 1 < 0){\n            setTrackIndex(tracks.length - 1);\n        } else {\n            setTrackIndex(trackIndex - 1);\n        }\n    }\n    \n    // NEXT - handles next track click\n    const toNextTrack = () => {\n        // if trackIndex is less than tracks length go to next track, otherwise go to first track\n        if (trackIndex < tracks.length -1){\n            setTrackIndex(trackIndex + 1);\n        } else {\n            setTrackIndex(0);\n        }\n    }\n    \n    // PLAY\n    useEffect(() => {\n        // when isPlaying changes:\n        // if isPlaying is true, play the track in audio tag \n        if(isPlaying) {\n            // update track for analyser\n            \n            audioRef.current.play();\n            // console.log('setting track')\n            onChangeTrack(audioRef.current)\n            startTimer();\n        } else {\n            // otherwise clear the intervalRef and pause the track in audio tag\n            console.log('pause track')\n            clearInterval(intervalRef.current)\n            audioRef.current.pause();\n            // onPauseTrack();\n        }\n    },[isPlaying, onChangeTrack])\n\n    useEffect(() => {\n        // pause and clean up on unmount / clear any setInterval timers\n\n        return () => {\n            audioRef.current.pause();\n            clearInterval(intervalRef.current);\n        }\n\n    }, [])\n\n    // NEXT track\n    useEffect(() => {\n        \n        // runs when trackIndex is updated, allowing current track to be paused while\n        // updating the value of audioRef to new source, resetting the progress state and \n        // setting new track to play\n\n        audioRef.current.pause()\n        audioRef.current = new Audio(audioSrc);\n        setTrackProgress(audioRef.current.currentTime);\n\n        if (isReady.current) {\n            audioRef.current.play();\n            setIsPlaying(true);\n            startTimer()\n        } else {\n            isReady.current = true;\n        }\n    }, [trackIndex])\n\n    const startTimer = () => {\n        // clear any timers already running\n        clearInterval(intervalRef.current);\n\n        // check track every second, if ended reset the player, otherwise update track progress\n        intervalRef.current = setInterval(() => {\n            if (audioRef.current.ended) {\n                setTrackProgress(0);\n                setIsPlaying(false);\n                console.log(\"player reset:\", audioRef.current)\n            } else {\n                setTrackProgress(audioRef.current.currentTime);\n            }\n        }, [1000])\n    }\n\n\n    const onScrub = (value) => {\n        // clear any timers already running\n        clearInterval(intervalRef.current);\n        audioRef.current.currentTime = value;\n        setTrackProgress(audioRef.current.currentTime);\n    }\n\n    const onScrubEnd = () => {\n        // if isPlayings value is false then set it to true\n        if (!isPlaying) {\n            setIsPlaying(true);\n        }\n        startTimer();\n    }   \n\n    return(\n        \n        <div className=\"audio-player\">\n            <div className=\"track-info\">\n                <h3 className=\"title\">{title}</h3>\n                <AudioControls\n                    isPlaying={isPlaying}\n                    onPrevClick={toPrevTrack}\n                    onNextClick={toNextTrack}\n                    onPlayPauseClick={setIsPlaying}\n                    // onPlay={toggleTrack}\n                />\n                <input \n                    type=\"range\"\n                    value={trackProgress}\n                    step=\"1\"\n                    min=\"0\"\n                    max={duration ? duration : `${duration}`}\n                    className=\"progress\"\n                    onChange={(e) => onScrub(e.target.value)}\n                    onMouseUp={onScrubEnd}\n                    onKeyUp={onScrubEnd}\n                    // style={{ background: trackStyling}}\n                />\n            </div>\n        </div>\n\n    ) \n            \n\n}\n\nexport default AudioPlayer;","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/AudioPlayer/AudioControls.jsx",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Visualisers/FrequencyVisualiser.js",["59"],"import React, { useRef, useEffect } from 'react';\n\n//let testWaveFormRef = useRef(Array.from({length: 1024}, () => Math.floor(Math.random() * 255)));\n//  const testWaveForm = testWaveFormRef.current;\n\nconst FrequencyVisualiser = ({ audioData, analyser, background }) => {\n\n    const canvasRef = useRef();\n\n    useEffect(() => {\n\n        let canvas = canvasRef.current;\n        let height = canvas.height;\n        let width = canvas.width;\n        let context = canvas.getContext('2d');\n        let randomColour = \"#\" + ((1 << 24) * Math.random() | 0).toString(16)\n\n        // a quarter of the fft size default\n        analyser.fftSize = 256;\n        console.log(analyser)\n        //bufferLength equals half the fftSize i.e. 128\n        let bufferLength = analyser.frequencyBinCount;\n        console.log(\"buffer length\", bufferLength);\n        // let dataArray = new Uint8Array(bufferLength);\n\n        context.clearRect(0, 0, width, height);\n\n        const render = () => {\n            if(background === \"Clear\"){\n                context.fillStyle = '#00aeb0';   \n            } else {\n                context.fillStyle = '#000000'\n            }\n            \n            context.fillRect(0, 0, width, height);\n\n            let barWidth = (width / bufferLength) * 2.5;\n            let barHeight;\n            let x = 0;\n\n            for (var i = 0; i < bufferLength; i++) {\n                // the height of a bar equals the current audio sample value halved\n                barHeight = audioData[i] / 0.3;\n                \n                context.fillStyle = randomColour;\n                context.fillRect(x, height - barHeight / 2, barWidth, barHeight)\n\n                x += barWidth + 1;\n            }\n        };\n\n        render()\n\n    }, [audioData]);\n\n    return (\n        <canvas\n            className=\"frequency-canvas\"\n            width=\"550\"\n            height=\"550\"\n            ref={canvasRef}\n        />\n    )\n\n}\n\nexport default FrequencyVisualiser;","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/Visualisers/WaveformVisualiser.js",["60"],"import React, {useRef, useEffect} from 'react';\n\n//let testWaveFormRef = useRef(Array.from({length: 1024}, () => Math.floor(Math.random() * 255)));\n//  const testWaveForm = testWaveFormRef.current;\n\nconst WaveformVisualiser = ({\n    audioData, \n    setAnalyserDisconnected, \n    analyserDisconnected,\n    background\n}) => {\n\n    const canvasRef = useRef();\n    \n    //clear the canvas every 30 seconds\n    // useEffect(() => {\n        \n    //     const clearCanvas = () => {\n    //         context.clearRect(0, 0, width, height);\n    //     }\n    //     setInterval(clearCanvas, 30000)\n\n    // },[])\n\n    useEffect(() => {\n        let canvas = canvasRef.current;\n        let height = canvas.height;\n        let width = canvas.width;\n        let context = canvas.getContext('2d');\n        let x = 0;\n        let sliceWidth = width / audioData.length;\n        let randomColour = \"#\" + ((1<<24)*Math.random() | 0).toString(16)\n        if(background === \"Black\"){\n            context.fillRect(0, 0,width, height)\n        } else {\n            context.fillStyle = '#000000'\n        }\n        \n        // if the analyser has been disconnected clear the canvas and reset analyserDisconnected to false\n        if(analyserDisconnected){\n            context.clearRect(0, 0, width, height);\n            setAnalyserDisconnected(false)\n        }\n        \n\n        const renderWaveform = () => {\n            \n            if(background === \"Black\"){\n                context.fillRect(0, 0,width, height)\n            } else {\n                context.fillStyle = '#000000'\n            }\n            \n            context.lineWidth = 2;\n            context.strokeStyle = randomColour;\n            \n            context.beginPath();\n            context.moveTo(0, height / 2);\n\n            for(const item of audioData) {\n                const y = (item / 255.0) * height;\n                context.lineTo(x, y);\n                x += sliceWidth;\n            }\n            // console.log(\"Audio-data:\", audioData)\n            context.lineTo(x, height / 2);\n            context.stroke();\n            \n        }\n        \n        renderWaveform()\n        \n\n    }, [audioData, background])\n\n    return(\n        <canvas \n            className=\"canvas\"\n            width=\"550\" \n            height=\"550\" \n            ref={canvasRef}\n        />\n    )\n\n}\n\nexport default WaveformVisualiser;","/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/containers/MediaPlayer.jsx",[],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/components/TrackForm/UploadForm.jsx",["61","62"],"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/client/src/services/TrackService.js",[],{"ruleId":"63","replacedBy":"64"},{"ruleId":"65","replacedBy":"66"},{"ruleId":"67","severity":1,"message":"68","line":32,"column":30,"nodeType":"69","endLine":32,"endColumn":74},{"ruleId":"67","severity":1,"message":"70","line":93,"column":8,"nodeType":"71","endLine":93,"endColumn":20,"suggestions":"72"},{"ruleId":"67","severity":1,"message":"73","line":54,"column":8,"nodeType":"71","endLine":54,"endColumn":19,"suggestions":"74"},{"ruleId":"67","severity":1,"message":"75","line":74,"column":8,"nodeType":"71","endLine":74,"endColumn":31,"suggestions":"76"},{"ruleId":"77","severity":1,"message":"78","line":1,"column":16,"nodeType":"79","messageId":"80","endLine":1,"endColumn":24},{"ruleId":"77","severity":1,"message":"81","line":1,"column":26,"nodeType":"79","messageId":"80","endLine":1,"endColumn":35},"no-native-reassign",["82"],"no-negated-in-lhs",["83"],"react-hooks/exhaustive-deps","Assignments to the 'source' variable from inside React Hook useEffect will be lost after each render. To preserve the value over time, store it in a useRef Hook and keep the mutable value in the '.current' property. Otherwise, you can move this variable directly inside useEffect.","CallExpression","React Hook useEffect has a missing dependency: 'audioSrc'. Either include it or remove the dependency array.","ArrayExpression",["84"],"React Hook useEffect has missing dependencies: 'analyser' and 'background'. Either include them or remove the dependency array.",["85"],"React Hook useEffect has missing dependencies: 'analyserDisconnected' and 'setAnalyserDisconnected'. Either include them or remove the dependency array. If 'setAnalyserDisconnected' changes too often, find the parent component that defines it and wrap that definition in useCallback.",["86"],"no-unused-vars","'useState' is defined but never used.","Identifier","unusedVar","'useEffect' is defined but never used.","no-global-assign","no-unsafe-negation",{"desc":"87","fix":"88"},{"desc":"89","fix":"90"},{"desc":"91","fix":"92"},"Update the dependencies array to be: [audioSrc, trackIndex]",{"range":"93","text":"94"},"Update the dependencies array to be: [analyser, audioData, background]",{"range":"95","text":"96"},"Update the dependencies array to be: [analyserDisconnected, audioData, background, setAnalyserDisconnected]",{"range":"97","text":"98"},[3178,3190],"[audioSrc, trackIndex]",[1737,1748],"[analyser, audioData, background]",[2133,2156],"[analyserDisconnected, audioData, background, setAnalyserDisconnected]"]