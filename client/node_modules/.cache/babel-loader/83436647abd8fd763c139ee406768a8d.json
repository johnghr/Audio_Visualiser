{"ast":null,"code":"var _jsxFileName = \"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/App.js\",\n    _s = $RefreshSig$();\n\nimport React, { useState, useRef } from 'react';\nimport AudioAnalyser from './components/Analysers/AudioAnalyser';\nimport AudioPlayer from './components/AudioPlayer';\nimport './App.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  //mode can be 'off', 'track' or 'microphone'\n  const [analyserState, setAnalyserState] = useState({\n    input: null,\n    mode: 'off'\n  });\n\n  async function getMicrophone() {\n    let micAudio = await navigator.mediaDevices.getUserMedia({\n      audio: true,\n      video: false\n    });\n    setMicrophoneStreaming(true);\n    setAnalyserState({\n      input: micAudio,\n      mode: \"microphone\"\n    });\n  }\n\n  function stopMicrophone() {\n    analyserState.input.getTracks().forEach(track => track.stop());\n    setAnalyserState({\n      input: null,\n      mode: 'off'\n    });\n    setMicrophoneStreaming(false);\n  }\n\n  function stopTrack() {\n    analyserState.input.getTracks().forEach(track => track.stop());\n    setAnalyserState(null);\n  }\n\n  function toggleMicrophone() {\n    if (analyserState.mode === 'microphone') {\n      stopMicrophone();\n    } else {\n      getMicrophone();\n    }\n  }\n\n  function toggleTrack(track) {\n    if (analyserState.mode === 'track') {\n      stopTrack();\n    } else {\n      setAnalyserState({\n        input: track,\n        mode: \"track\"\n      });\n    }\n  }\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"controls\",\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: toggleMicrophone,\n        children: microphoneInput ? 'Stop microphone' : 'Get microphone'\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 63,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 61,\n      columnNumber: 7\n    }, this), analyserState.input ? /*#__PURE__*/_jsxDEV(AudioAnalyser, {\n      input: analyserState.input,\n      mode: analyserState.mode\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 71,\n      columnNumber: 30\n    }, this) : \"\", /*#__PURE__*/_jsxDEV(AudioPlayer, {\n      toggleTrack: toggleTrack\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 73,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 59,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"MgG1xxux59jk1OoxNvy32V/J/JU=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/App.js"],"names":["React","useState","useRef","AudioAnalyser","AudioPlayer","App","analyserState","setAnalyserState","input","mode","getMicrophone","micAudio","navigator","mediaDevices","getUserMedia","audio","video","setMicrophoneStreaming","stopMicrophone","getTracks","forEach","track","stop","stopTrack","toggleMicrophone","toggleTrack","microphoneInput"],"mappings":";;;AAAA,OAAOA,KAAP,IAAeC,QAAf,EAAyBC,MAAzB,QAAsC,OAAtC;AACA,OAAOC,aAAP,MAA0B,sCAA1B;AACA,OAAOC,WAAP,MAAwB,0BAAxB;AACA,OAAO,WAAP;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AACb;AACA,QAAK,CAACC,aAAD,EAAgBC,gBAAhB,IAAoCN,QAAQ,CAAC;AAACO,IAAAA,KAAK,EAAE,IAAR;AAAcC,IAAAA,IAAI,EAAE;AAApB,GAAD,CAAjD;;AAEA,iBAAeC,aAAf,GAA+B;AAC7B,QAAIC,QAAQ,GAAG,MAAMC,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CACnB;AACEC,MAAAA,KAAK,EAAE,IADT;AAEEC,MAAAA,KAAK,EAAE;AAFT,KADmB,CAArB;AAMAC,IAAAA,sBAAsB,CAAC,IAAD,CAAtB;AACAV,IAAAA,gBAAgB,CAAC;AACfC,MAAAA,KAAK,EAAEG,QADQ;AAEfF,MAAAA,IAAI,EAAE;AAFS,KAAD,CAAhB;AAID;;AAED,WAASS,cAAT,GAA0B;AACxBZ,IAAAA,aAAa,CAACE,KAAd,CAAoBW,SAApB,GAAgCC,OAAhC,CAAwCC,KAAK,IAAIA,KAAK,CAACC,IAAN,EAAjD;AACAf,IAAAA,gBAAgB,CAAC;AAACC,MAAAA,KAAK,EAAE,IAAR;AAAcC,MAAAA,IAAI,EAAE;AAApB,KAAD,CAAhB;AACAQ,IAAAA,sBAAsB,CAAC,KAAD,CAAtB;AACD;;AAED,WAASM,SAAT,GAAqB;AACnBjB,IAAAA,aAAa,CAACE,KAAd,CAAoBW,SAApB,GAAgCC,OAAhC,CAAwCC,KAAK,IAAIA,KAAK,CAACC,IAAN,EAAjD;AACAf,IAAAA,gBAAgB,CAAC,IAAD,CAAhB;AACD;;AAED,WAASiB,gBAAT,GAA4B;AAC1B,QAAIlB,aAAa,CAACG,IAAd,KAAwB,YAA5B,EAAyC;AACvCS,MAAAA,cAAc;AACf,KAFD,MAEO;AACLR,MAAAA,aAAa;AACd;AACF;;AAED,WAASe,WAAT,CAAqBJ,KAArB,EAA4B;AAC1B,QAAIf,aAAa,CAACG,IAAd,KAAwB,OAA5B,EAAoC;AAClCc,MAAAA,SAAS;AACV,KAFD,MAEO;AACLhB,MAAAA,gBAAgB,CAAC;AACfC,QAAAA,KAAK,EAAEa,KADQ;AAEfZ,QAAAA,IAAI,EAAE;AAFS,OAAD,CAAhB;AAID;AAEF;;AAKD,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,4BAEE;AAAK,MAAA,SAAS,EAAC,UAAf;AAAA,6BAEE;AAAQ,QAAA,OAAO,EAAEe,gBAAjB;AAAA,kBACGE,eAAe,GAAG,iBAAH,GAAuB;AADzC;AAAA;AAAA;AAAA;AAAA;AAFF;AAAA;AAAA;AAAA;AAAA,YAFF,EAYGpB,aAAa,CAACE,KAAd,gBAAsB,QAAC,aAAD;AAAe,MAAA,KAAK,EAAEF,aAAa,CAACE,KAApC;AAA2C,MAAA,IAAI,EAAEF,aAAa,CAACG;AAA/D;AAAA;AAAA;AAAA;AAAA,YAAtB,GAA+F,EAZlG,eAcE,QAAC,WAAD;AAAa,MAAA,WAAW,EAAEgB;AAA1B;AAAA;AAAA;AAAA;AAAA,YAdF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAkBD;;GAtEQpB,G;;KAAAA,G;AAwET,eAAeA,GAAf","sourcesContent":["import React, {useState, useRef} from 'react';\nimport AudioAnalyser from './components/Analysers/AudioAnalyser';\nimport AudioPlayer from './components/AudioPlayer';\nimport './App.css';\n\nfunction App() {\n  //mode can be 'off', 'track' or 'microphone'\n  const[analyserState, setAnalyserState] = useState({input: null, mode: 'off'});\n\n  async function getMicrophone() {\n    let micAudio = await navigator.mediaDevices.getUserMedia(\n      {\n        audio: true,\n        video: false\n      }\n    )\n    setMicrophoneStreaming(true);\n    setAnalyserState({\n      input: micAudio,\n      mode: \"microphone\"\n    });\n  }\n\n  function stopMicrophone() {\n    analyserState.input.getTracks().forEach(track => track.stop());\n    setAnalyserState({input: null, mode: 'off'});\n    setMicrophoneStreaming(false);\n  }\n\n  function stopTrack() {\n    analyserState.input.getTracks().forEach(track => track.stop());\n    setAnalyserState(null);\n  }\n\n  function toggleMicrophone() {\n    if (analyserState.mode  === 'microphone'){\n      stopMicrophone();\n    } else {\n      getMicrophone();\n    }\n  }\n\n  function toggleTrack(track) {\n    if (analyserState.mode  === 'track'){\n      stopTrack();\n    } else {\n      setAnalyserState({\n        input: track,\n        mode: \"track\"\n      });\n    }\n    \n  }\n  \n\n  \n\n  return (\n    <div className=\"App\">\n      \n      <div className=\"controls\">\n        \n        <button onClick={toggleMicrophone}>\n          {microphoneInput ? 'Stop microphone' : 'Get microphone'}\n        </button>\n\n      </div>\n      {/* {microphoneInput ? <MicrophoneAnalyser microphoneInput={microphoneInput} /> : \"\"}\n      {trackInput ? <TrackAnalyser trackInput={trackInput} /> : \"\"} */}\n\n      {analyserState.input ? <AudioAnalyser input={analyserState.input} mode={analyserState.mode}/> : \"\"}\n\n      <AudioPlayer toggleTrack={toggleTrack}></AudioPlayer>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}