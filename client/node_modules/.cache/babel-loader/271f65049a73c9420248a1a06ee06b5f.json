{"ast":null,"code":"var _jsxFileName = \"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/App.js\",\n    _s = $RefreshSig$();\n\nimport React, { useState, useRef } from 'react';\nimport AAnalyser from './components/Analysers/MicrophoneAnalyser';\nimport AudioPlayer from './components/AudioPlayer';\nimport './App.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  const [microphoneInput, setMicrophoneInput] = useState(null);\n  const [trackInput, setTrackInput] = useState(null);\n  const [audioSource, setAudioSource] = useState(null);\n  const [analyserState, setAnalyserState] = useState(null);\n  const audioContextRef = useRef(new window.AudioContext() || window.webkitAudioContext)();\n  const audioContext = audioContextRef.current;\n  console.log(audioContext);\n\n  async function getMicrophone() {\n    let micAudio = await navigator.mediaDevices.getUserMedia({\n      audio: true,\n      video: false\n    });\n    setAnalyserState({\n      input: micAudio,\n      mode: \"microphone\"\n    });\n  }\n\n  function stopMicrophone() {\n    microphoneInput.getTracks().forEach(track => track.stop());\n    setMicrophoneInput(null);\n  }\n\n  function stopTrack() {\n    trackInput.getTracks().forEach(track => track.stop());\n    setTrackInput(null);\n  }\n\n  function toggleMicrophone() {\n    if (microphoneInput) {\n      stopMicrophone();\n    } else {\n      getMicrophone();\n    }\n  }\n\n  function toggleTrack(track) {\n    if (trackInput) {\n      stopTrack();\n    } else {\n      setAnalyserState({\n        input: track,\n        mode: \"microphone\"\n      });\n    }\n  }\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"controls\",\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: toggleMicrophone,\n        children: microphoneInput ? 'Stop microphone' : 'Get microphone'\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 67,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 65,\n      columnNumber: 7\n    }, this), analyserState.input ? /*#__PURE__*/_jsxDEV(AudioAnalyser, {\n      input: analyserState.input,\n      mode: analyserState.mode\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 75,\n      columnNumber: 30\n    }, this) : \"\", /*#__PURE__*/_jsxDEV(AudioPlayer, {\n      toggleTrack: toggleTrack\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 77,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 63,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"FaYa82xW0KAjtoeXco0jiG77SHo=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/App.js"],"names":["React","useState","useRef","AAnalyser","AudioPlayer","App","microphoneInput","setMicrophoneInput","trackInput","setTrackInput","audioSource","setAudioSource","analyserState","setAnalyserState","audioContextRef","window","AudioContext","webkitAudioContext","audioContext","current","console","log","getMicrophone","micAudio","navigator","mediaDevices","getUserMedia","audio","video","input","mode","stopMicrophone","getTracks","forEach","track","stop","stopTrack","toggleMicrophone","toggleTrack"],"mappings":";;;AAAA,OAAOA,KAAP,IAAeC,QAAf,EAAyBC,MAAzB,QAAsC,OAAtC;AACA,OAAOC,SAAP,MAAsB,2CAAtB;AACA,OAAOC,WAAP,MAAwB,0BAAxB;AACA,OAAO,WAAP;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AAEb,QAAK,CAACC,eAAD,EAAkBC,kBAAlB,IAAwCN,QAAQ,CAAC,IAAD,CAArD;AACA,QAAK,CAACO,UAAD,EAAaC,aAAb,IAA8BR,QAAQ,CAAC,IAAD,CAA3C;AACA,QAAK,CAACS,WAAD,EAAcC,cAAd,IAAgCV,QAAQ,CAAC,IAAD,CAA7C;AACA,QAAK,CAACW,aAAD,EAAgBC,gBAAhB,IAAoCZ,QAAQ,CAAC,IAAD,CAAjD;AACA,QAAMa,eAAe,GAAGZ,MAAM,CAAC,IAAIa,MAAM,CAACC,YAAX,MAA6BD,MAAM,CAACE,kBAArC,CAAN,EAAxB;AACA,QAAMC,YAAY,GAAGJ,eAAe,CAACK,OAArC;AACAC,EAAAA,OAAO,CAACC,GAAR,CAAYH,YAAZ;;AAEA,iBAAeI,aAAf,GAA+B;AAC7B,QAAIC,QAAQ,GAAG,MAAMC,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CACnB;AACEC,MAAAA,KAAK,EAAE,IADT;AAEEC,MAAAA,KAAK,EAAE;AAFT,KADmB,CAArB;AAMAf,IAAAA,gBAAgB,CAAC;AACfgB,MAAAA,KAAK,EAAEN,QADQ;AAEfO,MAAAA,IAAI,EAAE;AAFS,KAAD,CAAhB;AAID;;AAED,WAASC,cAAT,GAA0B;AACxBzB,IAAAA,eAAe,CAAC0B,SAAhB,GAA4BC,OAA5B,CAAoCC,KAAK,IAAIA,KAAK,CAACC,IAAN,EAA7C;AACA5B,IAAAA,kBAAkB,CAAC,IAAD,CAAlB;AACD;;AAED,WAAS6B,SAAT,GAAqB;AACnB5B,IAAAA,UAAU,CAACwB,SAAX,GAAuBC,OAAvB,CAA+BC,KAAK,IAAIA,KAAK,CAACC,IAAN,EAAxC;AACA1B,IAAAA,aAAa,CAAC,IAAD,CAAb;AACD;;AAED,WAAS4B,gBAAT,GAA4B;AAC1B,QAAI/B,eAAJ,EAAoB;AAClByB,MAAAA,cAAc;AACf,KAFD,MAEO;AACLT,MAAAA,aAAa;AACd;AACF;;AAED,WAASgB,WAAT,CAAqBJ,KAArB,EAA4B;AAC1B,QAAI1B,UAAJ,EAAe;AACb4B,MAAAA,SAAS;AACV,KAFD,MAEO;AACLvB,MAAAA,gBAAgB,CAAC;AACfgB,QAAAA,KAAK,EAAEK,KADQ;AAEfJ,QAAAA,IAAI,EAAE;AAFS,OAAD,CAAhB;AAID;AAEF;;AAKD,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,4BAEE;AAAK,MAAA,SAAS,EAAC,UAAf;AAAA,6BAEE;AAAQ,QAAA,OAAO,EAAEO,gBAAjB;AAAA,kBACG/B,eAAe,GAAG,iBAAH,GAAuB;AADzC;AAAA;AAAA;AAAA;AAAA;AAFF;AAAA;AAAA;AAAA;AAAA,YAFF,EAYGM,aAAa,CAACiB,KAAd,gBAAsB,QAAC,aAAD;AAAe,MAAA,KAAK,EAAEjB,aAAa,CAACiB,KAApC;AAA2C,MAAA,IAAI,EAAEjB,aAAa,CAACkB;AAA/D;AAAA;AAAA;AAAA;AAAA,YAAtB,GAA+F,EAZlG,eAcE,QAAC,WAAD;AAAa,MAAA,WAAW,EAAEQ;AAA1B;AAAA;AAAA;AAAA;AAAA,YAdF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAkBD;;GA1EQjC,G;;KAAAA,G;AA4ET,eAAeA,GAAf","sourcesContent":["import React, {useState, useRef} from 'react';\nimport AAnalyser from './components/Analysers/MicrophoneAnalyser';\nimport AudioPlayer from './components/AudioPlayer';\nimport './App.css';\n\nfunction App() {\n\n  const[microphoneInput, setMicrophoneInput] = useState(null);\n  const[trackInput, setTrackInput] = useState(null);\n  const[audioSource, setAudioSource] = useState(null);\n  const[analyserState, setAnalyserState] = useState(null);\n  const audioContextRef = useRef(new window.AudioContext() || window.webkitAudioContext)();\n  const audioContext = audioContextRef.current;\n  console.log(audioContext)\n\n  async function getMicrophone() {\n    let micAudio = await navigator.mediaDevices.getUserMedia(\n      {\n        audio: true,\n        video: false\n      }\n    )\n    setAnalyserState({\n      input: micAudio,\n      mode: \"microphone\"\n    });\n  }\n\n  function stopMicrophone() {\n    microphoneInput.getTracks().forEach(track => track.stop());\n    setMicrophoneInput(null);\n  }\n\n  function stopTrack() {\n    trackInput.getTracks().forEach(track => track.stop());\n    setTrackInput(null);\n  }\n\n  function toggleMicrophone() {\n    if (microphoneInput){\n      stopMicrophone();\n    } else {\n      getMicrophone();\n    }\n  }\n\n  function toggleTrack(track) {\n    if (trackInput){\n      stopTrack();\n    } else {\n      setAnalyserState({\n        input: track,\n        mode: \"microphone\"\n      });\n    }\n    \n  }\n  \n\n  \n\n  return (\n    <div className=\"App\">\n      \n      <div className=\"controls\">\n        \n        <button onClick={toggleMicrophone}>\n          {microphoneInput ? 'Stop microphone' : 'Get microphone'}\n        </button>\n\n      </div>\n      {/* {microphoneInput ? <MicrophoneAnalyser microphoneInput={microphoneInput} /> : \"\"}\n      {trackInput ? <TrackAnalyser trackInput={trackInput} /> : \"\"} */}\n\n      {analyserState.input ? <AudioAnalyser input={analyserState.input} mode={analyserState.mode}/> : \"\"}\n\n      <AudioPlayer toggleTrack={toggleTrack}></AudioPlayer>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}