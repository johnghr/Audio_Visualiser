{"ast":null,"code":"var _jsxFileName = \"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/components/AudioAnalyser.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect, useState } from 'react';\nimport AudioVisualiser from './AudioVisualiser';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nconst AudioAnalyser = ({\n  audioContextSource,\n  audioContext\n}) => {\n  _s();\n\n  const [dataArray, setDataArray] = useState(new Uint8Array());\n  const [audioData, setAudioData] = useState(null);\n  let analyser = audioContext.createAnalyser();\n  let rafId;\n  useEffect(() => {\n    // sets audio data to be a Uint8Array which is half as long as the analyser fftSize:\n    // determines the amount of data values available for visualisation\n    setDataArray(new Uint8Array(analyser.frequencyBinCount)); // connect the audio analyser to the source of audio\n\n    audioContextSource.connect(analyser);\n    tick(); // set the request animation frame Id for use when app dismounts/cancels\n\n    rafId = requestAnimationFrame(tick);\n  }, []);\n\n  let tick = () => {\n    // copies wave form data into the dataArray which is passed in as an argument   \n    analyser.getByteTimeDomainData(dataArray);\n    console.log(\"audio data\", audioData); // set AudioData to be data contained in dataArray so it can be passed down to\n    // visualiser as a prop\n\n    setAudioData(dataArray);\n    rafId = requestAnimationFrame(tick);\n  }; // function componentWillUnmount() {\n  //     cancelAnimationFrame(rafId);\n  //     analyser.disconnect();\n  //     source.disconnect();\n  // }\n\n\n  return /*#__PURE__*/_jsxDEV(AudioVisualiser, {\n    audioData: audioData\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 43,\n    columnNumber: 9\n  }, this);\n};\n\n_s(AudioAnalyser, \"E/+yujrbc3rFMIjslMPx0x/zkUg=\");\n\n_c = AudioAnalyser;\nexport default AudioAnalyser;\n\nvar _c;\n\n$RefreshReg$(_c, \"AudioAnalyser\");","map":{"version":3,"sources":["/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/components/AudioAnalyser.js"],"names":["React","useEffect","useState","AudioVisualiser","AudioAnalyser","audioContextSource","audioContext","dataArray","setDataArray","Uint8Array","audioData","setAudioData","analyser","createAnalyser","rafId","frequencyBinCount","connect","tick","requestAnimationFrame","getByteTimeDomainData","console","log"],"mappings":";;;AAAA,OAAOA,KAAP,IAAeC,SAAf,EAA0BC,QAA1B,QAAyC,OAAzC;AACA,OAAOC,eAAP,MAA4B,mBAA5B;;;AAGA,MAAMC,aAAa,GAAG,CAAC;AAAEC,EAAAA,kBAAF;AAAsBC,EAAAA;AAAtB,CAAD,KAA0C;AAAA;;AAE5D,QAAM,CAACC,SAAD,EAAYC,YAAZ,IAA4BN,QAAQ,CAAC,IAAIO,UAAJ,EAAD,CAA1C;AACA,QAAM,CAACC,SAAD,EAAYC,YAAZ,IAA4BT,QAAQ,CAAC,IAAD,CAA1C;AAEA,MAAIU,QAAQ,GAAGN,YAAY,CAACO,cAAb,EAAf;AACA,MAAIC,KAAJ;AAEAb,EAAAA,SAAS,CAAE,MAAM;AACb;AACA;AACAO,IAAAA,YAAY,CAAC,IAAIC,UAAJ,CAAeG,QAAQ,CAACG,iBAAxB,CAAD,CAAZ,CAHa,CAIb;;AACAV,IAAAA,kBAAkB,CAACW,OAAnB,CAA2BJ,QAA3B;AACAK,IAAAA,IAAI,GANS,CAOb;;AACAH,IAAAA,KAAK,GAAGI,qBAAqB,CAACD,IAAD,CAA7B;AACH,GATQ,EASN,EATM,CAAT;;AAYA,MAAIA,IAAI,GAAG,MAAM;AACb;AACAL,IAAAA,QAAQ,CAACO,qBAAT,CAA+BZ,SAA/B;AACAa,IAAAA,OAAO,CAACC,GAAR,CAAY,YAAZ,EAAyBX,SAAzB,EAHa,CAIb;AACA;;AACAC,IAAAA,YAAY,CAACJ,SAAD,CAAZ;AACAO,IAAAA,KAAK,GAAGI,qBAAqB,CAACD,IAAD,CAA7B;AACH,GARD,CApB4D,CA+B5D;AACA;AACA;AACA;AACA;;;AAEA,sBACI,QAAC,eAAD;AAAiB,IAAA,SAAS,EAAEP;AAA5B;AAAA;AAAA;AAAA;AAAA,UADJ;AAIH,CAzCD;;GAAMN,a;;KAAAA,a;AA2CN,eAAeA,aAAf","sourcesContent":["import React, {useEffect, useState} from 'react'\nimport AudioVisualiser from './AudioVisualiser'\n\n\nconst AudioAnalyser = ({ audioContextSource, audioContext }) => {\n\n    const [dataArray, setDataArray] = useState(new Uint8Array());\n    const [audioData, setAudioData] = useState(null)\n\n    let analyser = audioContext.createAnalyser();\n    let rafId;\n    \n    useEffect( () => {\n        // sets audio data to be a Uint8Array which is half as long as the analyser fftSize:\n        // determines the amount of data values available for visualisation\n        setDataArray(new Uint8Array(analyser.frequencyBinCount)) ;\n        // connect the audio analyser to the source of audio\n        audioContextSource.connect(analyser);\n        tick();\n        // set the request animation frame Id for use when app dismounts/cancels\n        rafId = requestAnimationFrame(tick);\n    }, [])\n\n    \n    let tick = () => {\n        // copies wave form data into the dataArray which is passed in as an argument   \n        analyser.getByteTimeDomainData(dataArray);\n        console.log(\"audio data\",audioData)\n        // set AudioData to be data contained in dataArray so it can be passed down to\n        // visualiser as a prop\n        setAudioData(dataArray);\n        rafId = requestAnimationFrame(tick);\n    }\n\n\n    // function componentWillUnmount() {\n    //     cancelAnimationFrame(rafId);\n    //     analyser.disconnect();\n    //     source.disconnect();\n    // }\n\n    return(\n        <AudioVisualiser audioData={audioData}/>\n    )\n\n}\n\nexport default AudioAnalyser;"]},"metadata":{},"sourceType":"module"}