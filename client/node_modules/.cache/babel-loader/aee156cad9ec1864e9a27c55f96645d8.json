{"ast":null,"code":"var _jsxFileName = \"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/App.js\",\n    _s = $RefreshSig$();\n\nimport React, { useState, useRef } from 'react';\nimport AudioAnalyser from './components/AudioAnalyser';\nimport './App.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  const [source, setSource] = useState(null); // const[audio, setAudio] = useState(null);\n\n  const audioContextRef = useRef(new (window.AudioContext || window.webkitAudioContext)());\n  const audioContext = audioContextRef.current;\n\n  async function getMicrophone() {\n    let audio = await navigator.mediaDevices.getUserMedia({\n      audio: true,\n      video: false\n    }); // setAudio(audio);\n\n    setSource(audioContext.createMediaStreamSource(audio));\n  }\n\n  function stopMicrophone() {\n    source.getTracks().forEach(track => track.stop());\n    setSource(null);\n  }\n\n  function toggleMicrophone() {\n    if (dou) {\n      stopMicrophone();\n    } else {\n      getMicrophone();\n    }\n  }\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"controls\",\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: toggleMicrophone,\n        children: audio ? 'Stop microphone' : 'Get microphone'\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 41,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 39,\n      columnNumber: 7\n    }, this), source ? /*#__PURE__*/_jsxDEV(AudioAnalyser, {\n      source: source,\n      audioContext: audioContext\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 46,\n      columnNumber: 17\n    }, this) : \"\"]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 37,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"5d3nk5ZZHdVncVvr34evAzG8oks=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/App.js"],"names":["React","useState","useRef","AudioAnalyser","App","source","setSource","audioContextRef","window","AudioContext","webkitAudioContext","audioContext","current","getMicrophone","audio","navigator","mediaDevices","getUserMedia","video","createMediaStreamSource","stopMicrophone","getTracks","forEach","track","stop","toggleMicrophone","dou"],"mappings":";;;AAAA,OAAOA,KAAP,IAAeC,QAAf,EAAyBC,MAAzB,QAAsC,OAAtC;AACA,OAAOC,aAAP,MAA0B,4BAA1B;AACA,OAAO,WAAP;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AAEb,QAAK,CAACC,MAAD,EAASC,SAAT,IAAsBL,QAAQ,CAAC,IAAD,CAAnC,CAFa,CAGb;;AACA,QAAMM,eAAe,GAAGL,MAAM,CAAC,KAAKM,MAAM,CAACC,YAAP,IAAuBD,MAAM,CAACE,kBAAnC,GAAD,CAA9B;AACA,QAAMC,YAAY,GAAGJ,eAAe,CAACK,OAArC;;AAEA,iBAAeC,aAAf,GAA+B;AAC7B,QAAIC,KAAK,GAAG,MAAMC,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAChB;AACEH,MAAAA,KAAK,EAAE,IADT;AAEEI,MAAAA,KAAK,EAAE;AAFT,KADgB,CAAlB,CAD6B,CAO7B;;AACAZ,IAAAA,SAAS,CAACK,YAAY,CAACQ,uBAAb,CAAqCL,KAArC,CAAD,CAAT;AACD;;AAED,WAASM,cAAT,GAA0B;AACxBf,IAAAA,MAAM,CAACgB,SAAP,GAAmBC,OAAnB,CAA2BC,KAAK,IAAIA,KAAK,CAACC,IAAN,EAApC;AACAlB,IAAAA,SAAS,CAAC,IAAD,CAAT;AACD;;AAED,WAASmB,gBAAT,GAA4B;AAC1B,QAAGC,GAAH,EAAO;AACLN,MAAAA,cAAc;AACf,KAFD,MAEO;AACLP,MAAAA,aAAa;AACd;AACF;;AAED,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,4BAEE;AAAK,MAAA,SAAS,EAAC,UAAf;AAAA,6BAEE;AAAQ,QAAA,OAAO,EAAEY,gBAAjB;AAAA,kBACGX,KAAK,GAAG,iBAAH,GAAuB;AAD/B;AAAA;AAAA;AAAA;AAAA;AAFF;AAAA;AAAA;AAAA;AAAA,YAFF,EASGT,MAAM,gBAAG,QAAC,aAAD;AAAe,MAAA,MAAM,EAAEA,MAAvB;AAA+B,MAAA,YAAY,EAAEM;AAA7C;AAAA;AAAA;AAAA;AAAA,YAAH,GAAkE,EAT3E;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAaD;;GA5CQP,G;;KAAAA,G;AA8CT,eAAeA,GAAf","sourcesContent":["import React, {useState, useRef} from 'react';\nimport AudioAnalyser from './components/AudioAnalyser';\nimport './App.css';\n\nfunction App() {\n\n  const[source, setSource] = useState(null);\n  // const[audio, setAudio] = useState(null);\n  const audioContextRef = useRef(new (window.AudioContext || window.webkitAudioContext)());\n  const audioContext = audioContextRef.current;\n\n  async function getMicrophone() {\n    let audio = await navigator.mediaDevices.getUserMedia(\n      {\n        audio: true,\n        video: false\n      }\n    )\n    // setAudio(audio);\n    setSource(audioContext.createMediaStreamSource(audio));\n  }\n\n  function stopMicrophone() {\n    source.getTracks().forEach(track => track.stop());\n    setSource(null);\n  }\n\n  function toggleMicrophone() {\n    if(dou){\n      stopMicrophone();\n    } else {\n      getMicrophone();\n    }\n  }\n\n  return (\n    <div className=\"App\">\n      \n      <div className=\"controls\">\n        \n        <button onClick={toggleMicrophone}>\n          {audio ? 'Stop microphone' : 'Get microphone'}\n        </button>\n\n      </div>\n      {source ? <AudioAnalyser source={source} audioContext={audioContext}/> : \"\"}\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}