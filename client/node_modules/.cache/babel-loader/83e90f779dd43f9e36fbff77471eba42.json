{"ast":null,"code":"var _jsxFileName = \"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/App.js\",\n    _s = $RefreshSig$();\n\n// import React, {useState, useRef} from 'react';\nimport AudioAnalyser from './components/AudioAnalyser';\nimport AudioPlayer from './components/AudioPlayer';\nimport './App.css';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nfunction App() {\n  _s();\n\n  const [audioInput, setAudioInput] = useState(null); // const audioContextRef = useRef(new (window.AudioContext || window.webkitAudioContext)())\n  // const audioContext = audioContextRef.current;\n\n  const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n  const analyser = audioContext.creatAnalyser();\n\n  async function getMicrophone() {\n    let micAudio = await navigator.mediaDevices.getUserMedia({\n      audio: true,\n      video: false\n    });\n    setAudioInput(audioContext.createMediaStreamSource(micAudio));\n    console.log(\"audio input:\", audioInput);\n  }\n\n  function stopTracks() {\n    audioInput.getTracks().forEach(track => track.stop());\n    setAudioInput(null);\n  }\n\n  function toggleMicrophone() {\n    if (audioInput) {\n      stopTracks();\n    } else {\n      getMicrophone();\n    }\n  }\n\n  function getAudioTrack(event) {\n    if (audioInput) {\n      stopTracks();\n    } else {\n      console.log(\"Event target:\", event.target);\n      const elementSource = audioContext.createMediaElementSource(event.target);\n      setAudioInput(elementSource);\n    }\n  }\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"controls\",\n      children: /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: toggleMicrophone,\n        children: audioInput ? 'Stop microphone' : 'Get microphone'\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 56,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 54,\n      columnNumber: 7\n    }, this), audioInput ? /*#__PURE__*/_jsxDEV(AudioAnalyser, {\n      audioInput: audioInput,\n      analyser: analyser\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 61,\n      columnNumber: 21\n    }, this) : \"\", /*#__PURE__*/_jsxDEV(AudioPlayer, {\n      onPlay: getAudioTrack\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 62,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 52,\n    columnNumber: 5\n  }, this);\n}\n\n_s(App, \"3RwubXsrLpBzmMPup6jcc3577gE=\");\n\n_c = App;\nexport default App;\n\nvar _c;\n\n$RefreshReg$(_c, \"App\");","map":{"version":3,"sources":["/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/App.js"],"names":["AudioAnalyser","AudioPlayer","App","audioInput","setAudioInput","useState","audioContext","window","AudioContext","webkitAudioContext","analyser","creatAnalyser","getMicrophone","micAudio","navigator","mediaDevices","getUserMedia","audio","video","createMediaStreamSource","console","log","stopTracks","getTracks","forEach","track","stop","toggleMicrophone","getAudioTrack","event","target","elementSource","createMediaElementSource"],"mappings":";;;AAAA;AACA,OAAOA,aAAP,MAA0B,4BAA1B;AACA,OAAOC,WAAP,MAAwB,0BAAxB;AACA,OAAO,WAAP;;;AAEA,SAASC,GAAT,GAAe;AAAA;;AAEb,QAAK,CAACC,UAAD,EAAaC,aAAb,IAA8BC,QAAQ,CAAC,IAAD,CAA3C,CAFa,CAGb;AACA;;AACA,QAAMC,YAAY,GAAG,KAAKC,MAAM,CAACC,YAAP,IAAuBD,MAAM,CAACE,kBAAnC,GAArB;AACA,QAAMC,QAAQ,GAAGJ,YAAY,CAACK,aAAb,EAAjB;;AAEA,iBAAeC,aAAf,GAA+B;AAC7B,QAAIC,QAAQ,GAAG,MAAMC,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CACnB;AACEC,MAAAA,KAAK,EAAE,IADT;AAEEC,MAAAA,KAAK,EAAE;AAFT,KADmB,CAArB;AAOAd,IAAAA,aAAa,CAACE,YAAY,CAACa,uBAAb,CAAqCN,QAArC,CAAD,CAAb;AACAO,IAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ,EAA4BlB,UAA5B;AACD;;AAED,WAASmB,UAAT,GAAsB;AACpBnB,IAAAA,UAAU,CAACoB,SAAX,GAAuBC,OAAvB,CAA+BC,KAAK,IAAIA,KAAK,CAACC,IAAN,EAAxC;AACAtB,IAAAA,aAAa,CAAC,IAAD,CAAb;AACD;;AAED,WAASuB,gBAAT,GAA4B;AAC1B,QAAGxB,UAAH,EAAc;AACZmB,MAAAA,UAAU;AACX,KAFD,MAEO;AACLV,MAAAA,aAAa;AACd;AACF;;AAED,WAASgB,aAAT,CAAuBC,KAAvB,EAA8B;AAC5B,QAAG1B,UAAH,EAAc;AACZmB,MAAAA,UAAU;AACX,KAFD,MAEO;AACLF,MAAAA,OAAO,CAACC,GAAR,CAAY,eAAZ,EAA6BQ,KAAK,CAACC,MAAnC;AACA,YAAMC,aAAa,GAAGzB,YAAY,CAAC0B,wBAAb,CAAsCH,KAAK,CAACC,MAA5C,CAAtB;AACA1B,MAAAA,aAAa,CAAC2B,aAAD,CAAb;AACD;AACF;;AAID,sBACE;AAAK,IAAA,SAAS,EAAC,KAAf;AAAA,4BAEE;AAAK,MAAA,SAAS,EAAC,UAAf;AAAA,6BAEE;AAAQ,QAAA,OAAO,EAAEJ,gBAAjB;AAAA,kBACGxB,UAAU,GAAG,iBAAH,GAAuB;AADpC;AAAA;AAAA;AAAA;AAAA;AAFF;AAAA;AAAA;AAAA;AAAA,YAFF,EASGA,UAAU,gBAAG,QAAC,aAAD;AAAe,MAAA,UAAU,EAAEA,UAA3B;AAAuC,MAAA,QAAQ,EAAEO;AAAjD;AAAA;AAAA;AAAA;AAAA,YAAH,GAAkE,EAT/E,eAUE,QAAC,WAAD;AAAa,MAAA,MAAM,EAAEkB;AAArB;AAAA;AAAA;AAAA;AAAA,YAVF;AAAA;AAAA;AAAA;AAAA;AAAA,UADF;AAcD;;GA3DQ1B,G;;KAAAA,G;AA6DT,eAAeA,GAAf","sourcesContent":["// import React, {useState, useRef} from 'react';\nimport AudioAnalyser from './components/AudioAnalyser'\nimport AudioPlayer from './components/AudioPlayer'\nimport './App.css';\n\nfunction App() {\n\n  const[audioInput, setAudioInput] = useState(null);\n  // const audioContextRef = useRef(new (window.AudioContext || window.webkitAudioContext)())\n  // const audioContext = audioContextRef.current;\n  const audioContext = new (window.AudioContext || window.webkitAudioContext)(); \n  const analyser = audioContext.creatAnalyser();\n\n  async function getMicrophone() {\n    let micAudio = await navigator.mediaDevices.getUserMedia(\n      {\n        audio: true,\n        video: false\n      }\n    )\n     ;\n    setAudioInput(audioContext.createMediaStreamSource(micAudio));\n    console.log(\"audio input:\", audioInput)\n  }\n\n  function stopTracks() {\n    audioInput.getTracks().forEach(track => track.stop());\n    setAudioInput(null);\n  }\n\n  function toggleMicrophone() {\n    if(audioInput){\n      stopTracks();\n    } else {\n      getMicrophone();\n    }\n  }\n\n  function getAudioTrack(event) {\n    if(audioInput){\n      stopTracks();\n    } else {\n      console.log(\"Event target:\", event.target)\n      const elementSource = audioContext.createMediaElementSource(event.target)\n      setAudioInput(elementSource);\n    }\n  }\n\n  \n\n  return (\n    <div className=\"App\">\n      \n      <div className=\"controls\">\n        \n        <button onClick={toggleMicrophone}>\n          {audioInput ? 'Stop microphone' : 'Get microphone'}\n        </button>\n\n      </div>\n      {audioInput ? <AudioAnalyser audioInput={audioInput} analyser={analyser}/> : \"\"}\n      <AudioPlayer onPlay={getAudioTrack}></AudioPlayer>\n    </div>\n  );\n}\n\nexport default App;\n"]},"metadata":{},"sourceType":"module"}