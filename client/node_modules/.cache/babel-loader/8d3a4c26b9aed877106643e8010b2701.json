{"ast":null,"code":"var _jsxFileName = \"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/components/Analysers/AudioAnalyser.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect, useState, useRef } from 'react';\nimport WaveformVisualiser from '../Visualisers/WaveformVisualiser';\nimport FrequencyVisualiser from '../Visualisers/FrequencyVisualiser';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nconst AudioAnalyser = ({\n  mode,\n  input\n}) => {\n  _s();\n\n  const [audioData, setAudioData] = useState(new Uint8Array(0));\n  const audioContext = new (window.AudioContext || window.webkitAudioContext)(); // creates analyser node\n  //const analyser = audioContext.createAnalyser();\n  //remove this probably\n\n  const sourceRef = useRef(null);\n  let source = sourceRef.current;\n  const analyserRef = useRef(audioContext.createAnalyser());\n  const analyser = analyserRef.current; //\n\n  useEffect(() => {\n    console.log('analyser input', input); // empty request animation frame Id\n\n    let rafId; // creates an audio context\n    // Creates a data Array which is half the length of the fftSize;\n    // it takes in unsigned integers  \n\n    const dataArray = new Uint8Array(analyser.frequencyBinCount); // connects the audio stream to the analyser node\n    //let source;\n\n    if (mode === \"track\") {\n      source = audioContext.createMediaElementSource(input);\n      source.connect(analyser).connect(audioContext.destination);\n    } else {\n      source = audioContext.createMediaStreamSource(input);\n      source.connect(analyser);\n    }\n\n    const tick = () => {\n      // copies wave form data into the dataArray which is passed in as an argument   \n      analyser.getByteTimeDomainData(dataArray); // sets audioData to be the value of a copy of dataArray\n      // console.log(\"audio data:\",dataArray)\n\n      setAudioData([...dataArray]); // requests a re-render while calling tick in a recursive loop\n\n      rafId = requestAnimationFrame(tick);\n    };\n\n    rafId = requestAnimationFrame(tick);\n    return function cleanup() {\n      if (mode === \"track\") {\n        console.log('input', input);\n        console.log('analyser', analyser);\n        console.log('context', audioContext);\n        source.disconnect(analyser).disconnect(audioContext.destination);\n      } else {//source.disconnect()\n      }\n\n      cancelAnimationFrame(rafId);\n      console.log('clean up on aisle 3');\n    };\n  }, [mode, input]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: /*#__PURE__*/_jsxDEV(WaveformVisualiser, {\n      audioData: audioData\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 70,\n      columnNumber: 13\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 69,\n    columnNumber: 9\n  }, this);\n};\n\n_s(AudioAnalyser, \"WjLJk9/FrFoIpFRETPHSWUuhZgg=\");\n\n_c = AudioAnalyser;\nexport default AudioAnalyser;\n\nvar _c;\n\n$RefreshReg$(_c, \"AudioAnalyser\");","map":{"version":3,"sources":["/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/components/Analysers/AudioAnalyser.js"],"names":["React","useEffect","useState","useRef","WaveformVisualiser","FrequencyVisualiser","AudioAnalyser","mode","input","audioData","setAudioData","Uint8Array","audioContext","window","AudioContext","webkitAudioContext","sourceRef","source","current","analyserRef","createAnalyser","analyser","console","log","rafId","dataArray","frequencyBinCount","createMediaElementSource","connect","destination","createMediaStreamSource","tick","getByteTimeDomainData","requestAnimationFrame","cleanup","disconnect","cancelAnimationFrame"],"mappings":";;;AAAA,OAAOA,KAAP,IAAeC,SAAf,EAA0BC,QAA1B,EAAoCC,MAApC,QAAiD,OAAjD;AACA,OAAOC,kBAAP,MAA+B,mCAA/B;AACA,OAAOC,mBAAP,MAAgC,oCAAhC;;;AAEA,MAAMC,aAAa,GAAG,CAAC;AAAEC,EAAAA,IAAF;AAAQC,EAAAA;AAAR,CAAD,KAAqB;AAAA;;AAEvC,QAAM,CAACC,SAAD,EAAYC,YAAZ,IAA4BR,QAAQ,CAAC,IAAIS,UAAJ,CAAe,CAAf,CAAD,CAA1C;AAEA,QAAMC,YAAY,GAAG,KAAKC,MAAM,CAACC,YAAP,IAAuBD,MAAM,CAACE,kBAAnC,GAArB,CAJuC,CAKvC;AACA;AAEA;;AACI,QAAMC,SAAS,GAAGb,MAAM,CAAC,IAAD,CAAxB;AACA,MAAIc,MAAM,GAAGD,SAAS,CAACE,OAAvB;AACA,QAAMC,WAAW,GAAGhB,MAAM,CAACS,YAAY,CAACQ,cAAb,EAAD,CAA1B;AACA,QAAMC,QAAQ,GAAGF,WAAW,CAACD,OAA7B,CAZmC,CAavC;;AAGAjB,EAAAA,SAAS,CAAE,MAAM;AACbqB,IAAAA,OAAO,CAACC,GAAR,CAAY,gBAAZ,EAA8Bf,KAA9B,EADa,CAEb;;AACA,QAAIgB,KAAJ,CAHa,CAKb;AAEA;AACA;;AACA,UAAMC,SAAS,GAAG,IAAId,UAAJ,CAAeU,QAAQ,CAACK,iBAAxB,CAAlB,CATa,CAUb;AACA;;AACA,QAAGnB,IAAI,KAAK,OAAZ,EAAoB;AAChBU,MAAAA,MAAM,GAAGL,YAAY,CAACe,wBAAb,CAAsCnB,KAAtC,CAAT;AACAS,MAAAA,MAAM,CAACW,OAAP,CAAeP,QAAf,EAAyBO,OAAzB,CAAiChB,YAAY,CAACiB,WAA9C;AACH,KAHD,MAGO;AACHZ,MAAAA,MAAM,GAAGL,YAAY,CAACkB,uBAAb,CAAqCtB,KAArC,CAAT;AACAS,MAAAA,MAAM,CAACW,OAAP,CAAeP,QAAf;AACH;;AAED,UAAMU,IAAI,GAAG,MAAM;AACf;AACAV,MAAAA,QAAQ,CAACW,qBAAT,CAA+BP,SAA/B,EAFe,CAGf;AACA;;AACAf,MAAAA,YAAY,CAAC,CAAC,GAAGe,SAAJ,CAAD,CAAZ,CALe,CAMf;;AACAD,MAAAA,KAAK,GAAGS,qBAAqB,CAACF,IAAD,CAA7B;AACH,KARD;;AAUAP,IAAAA,KAAK,GAAGS,qBAAqB,CAACF,IAAD,CAA7B;AAEA,WAAO,SAASG,OAAT,GAAmB;AACtB,UAAG3B,IAAI,KAAK,OAAZ,EAAoB;AAChBe,QAAAA,OAAO,CAACC,GAAR,CAAY,OAAZ,EAAqBf,KAArB;AACAc,QAAAA,OAAO,CAACC,GAAR,CAAY,UAAZ,EAAwBF,QAAxB;AACAC,QAAAA,OAAO,CAACC,GAAR,CAAY,SAAZ,EAAuBX,YAAvB;AACAK,QAAAA,MAAM,CAACkB,UAAP,CAAkBd,QAAlB,EAA4Bc,UAA5B,CAAuCvB,YAAY,CAACiB,WAApD;AACH,OALD,MAKO,CACH;AACH;;AACDO,MAAAA,oBAAoB,CAACZ,KAAD,CAApB;AACAF,MAAAA,OAAO,CAACC,GAAR,CAAY,qBAAZ;AACH,KAXD;AAaH,GA7CQ,EA6CN,CAAChB,IAAD,EAAOC,KAAP,CA7CM,CAAT;AA+CA,sBACI;AAAA,2BACI,QAAC,kBAAD;AAAoB,MAAA,SAAS,EAAEC;AAA/B;AAAA;AAAA;AAAA;AAAA;AADJ;AAAA;AAAA;AAAA;AAAA,UADJ;AAQH,CAvED;;GAAMH,a;;KAAAA,a;AAyEN,eAAeA,aAAf","sourcesContent":["import React, {useEffect, useState, useRef} from 'react';\nimport WaveformVisualiser from '../Visualisers/WaveformVisualiser';\nimport FrequencyVisualiser from '../Visualisers/FrequencyVisualiser';\n\nconst AudioAnalyser = ({ mode, input }) => {\n\n    const [audioData, setAudioData] = useState(new Uint8Array(0));\n        \n    const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n    // creates analyser node\n    //const analyser = audioContext.createAnalyser();\n\n    //remove this probably\n        const sourceRef = useRef(null);\n        let source = sourceRef.current;\n        const analyserRef = useRef(audioContext.createAnalyser())\n        const analyser = analyserRef.current;\n    //\n\n\n    useEffect( () => {\n        console.log('analyser input', input)\n        // empty request animation frame Id\n        let rafId; \n        \n        // creates an audio context\n        \n        // Creates a data Array which is half the length of the fftSize;\n        // it takes in unsigned integers  \n        const dataArray = new Uint8Array(analyser.frequencyBinCount);\n        // connects the audio stream to the analyser node\n        //let source;\n        if(mode === \"track\"){\n            source = audioContext.createMediaElementSource(input);\n            source.connect(analyser).connect(audioContext.destination);\n        } else {\n            source = audioContext.createMediaStreamSource(input);\n            source.connect(analyser);\n        }\n        \n        const tick = () => {\n            // copies wave form data into the dataArray which is passed in as an argument   \n            analyser.getByteTimeDomainData(dataArray)\n            // sets audioData to be the value of a copy of dataArray\n            // console.log(\"audio data:\",dataArray)\n            setAudioData([...dataArray])\n            // requests a re-render while calling tick in a recursive loop\n            rafId = requestAnimationFrame(tick);\n        }\n    \n        rafId = requestAnimationFrame(tick);\n\n        return function cleanup() {\n            if(mode === \"track\"){\n                console.log('input', input);\n                console.log('analyser', analyser);\n                console.log('context', audioContext);\n                source.disconnect(analyser).disconnect(audioContext.destination)\n            } else {\n                //source.disconnect()\n            }\n            cancelAnimationFrame(rafId);\n            console.log('clean up on aisle 3')   \n        }\n\n    }, [mode, input])\n\n    return(\n        <div>\n            <WaveformVisualiser audioData={audioData}/>\n            {/* <FrequencyVisualiser audioData={audioData} analyser={analyser}/>  */}\n        </div>\n        \n    )\n\n}\n\nexport default AudioAnalyser;"]},"metadata":{},"sourceType":"module"}