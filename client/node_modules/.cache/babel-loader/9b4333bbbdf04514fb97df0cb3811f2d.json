{"ast":null,"code":"var _jsxFileName = \"/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/components/Analysers/MicrophoneAnalyser.js\",\n    _s = $RefreshSig$();\n\nimport React, { useEffect, useState } from 'react';\nimport WaveformVisualiser from '../Visualisers/WaveformVisualiser';\nimport FrequencyVisualiser from '../Visualisers/FrequencyVisualiser';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n\nconst MicAudioAnalyser = ({\n  microphoneInput\n}) => {\n  _s();\n\n  const [audioData, setAudioData] = useState(new Uint8Array(0)); // creates an audio context\n\n  const audioContext = new (window.AudioContext || window.webkitAudioContext)(); // creates analyser node\n\n  const analyser = audioContext.createAnalyser();\n  useEffect(() => {\n    // empty request animation frame Id\n    let rafId; // Creates a data Array which is half the length of the fftSize\n    // it takes in unsigned integers  \n\n    const dataArray = new Uint8Array(analyser.frequencyBinCount); // creates a source variable containing the media stream source\n\n    const source = audioContext.createMediaStreamSource(microphoneInput); // connects the audio stream to the analyser node\n\n    source.connect(analyser);\n\n    const tick = () => {\n      // copies wave form data into the dataArray which is passed in as an argument   \n      analyser.getByteTimeDomainData(dataArray); // sets audioData to be the value of a copy of dataArray\n\n      console.log(\"audio data:\", dataArray);\n      setAudioData([...dataArray]); // requests a re-render while calling tick in a recursive loop\n\n      rafId = requestAnimationFrame(tick);\n    };\n\n    rafId = requestAnimationFrame(tick);\n    return function cleanup() {\n      cancelAnimationFrame(rafId);\n    };\n  }, [microphoneInput]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(WaveformVisualiser, {\n      audioData: audioData\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 48,\n      columnNumber: 13\n    }, this), /*#__PURE__*/_jsxDEV(FrequencyVisualiser, {\n      audioData: audioData,\n      analyser: analyser\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 49,\n      columnNumber: 13\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 47,\n    columnNumber: 9\n  }, this);\n};\n\n_s(MicAudioAnalyser, \"vp759RvJ0/M2OESOZvwirEnYLkY=\");\n\n_c = MicAudioAnalyser;\nexport default MicAudioAnalyser;\n\nvar _c;\n\n$RefreshReg$(_c, \"MicAudioAnalyser\");","map":{"version":3,"sources":["/Users/john/codeclan_work/final_project/full_stack_audio_processing_with_functions/audio_processing/src/components/Analysers/MicrophoneAnalyser.js"],"names":["React","useEffect","useState","WaveformVisualiser","FrequencyVisualiser","MicAudioAnalyser","microphoneInput","audioData","setAudioData","Uint8Array","audioContext","window","AudioContext","webkitAudioContext","analyser","createAnalyser","rafId","dataArray","frequencyBinCount","source","createMediaStreamSource","connect","tick","getByteTimeDomainData","console","log","requestAnimationFrame","cleanup","cancelAnimationFrame"],"mappings":";;;AAAA,OAAOA,KAAP,IAAeC,SAAf,EAA0BC,QAA1B,QAAyC,OAAzC;AACA,OAAOC,kBAAP,MAA+B,mCAA/B;AACA,OAAOC,mBAAP,MAAgC,oCAAhC;;;AAGC,MAAMC,gBAAgB,GAAG,CAAC;AAAEC,EAAAA;AAAF,CAAD,KAAyB;AAAA;;AAE/C,QAAM,CAACC,SAAD,EAAYC,YAAZ,IAA4BN,QAAQ,CAAC,IAAIO,UAAJ,CAAe,CAAf,CAAD,CAA1C,CAF+C,CAG/C;;AACA,QAAMC,YAAY,GAAG,KAAKC,MAAM,CAACC,YAAP,IAAuBD,MAAM,CAACE,kBAAnC,GAArB,CAJ+C,CAK/C;;AACA,QAAMC,QAAQ,GAAGJ,YAAY,CAACK,cAAb,EAAjB;AAEAd,EAAAA,SAAS,CAAE,MAAM;AACb;AACA,QAAIe,KAAJ,CAFa,CAMb;AACA;;AACA,UAAMC,SAAS,GAAG,IAAIR,UAAJ,CAAeK,QAAQ,CAACI,iBAAxB,CAAlB,CARa,CAUb;;AACA,UAAMC,MAAM,GAAGT,YAAY,CAACU,uBAAb,CAAqCd,eAArC,CAAf,CAXa,CAYb;;AACAa,IAAAA,MAAM,CAACE,OAAP,CAAeP,QAAf;;AACA,UAAMQ,IAAI,GAAG,MAAM;AACf;AACAR,MAAAA,QAAQ,CAACS,qBAAT,CAA+BN,SAA/B,EAFe,CAGf;;AACAO,MAAAA,OAAO,CAACC,GAAR,CAAY,aAAZ,EAA0BR,SAA1B;AACAT,MAAAA,YAAY,CAAC,CAAC,GAAGS,SAAJ,CAAD,CAAZ,CALe,CAMf;;AACAD,MAAAA,KAAK,GAAGU,qBAAqB,CAACJ,IAAD,CAA7B;AACH,KARD;;AAUAN,IAAAA,KAAK,GAAGU,qBAAqB,CAACJ,IAAD,CAA7B;AAEA,WAAO,SAASK,OAAT,GAAmB;AACtBC,MAAAA,oBAAoB,CAACZ,KAAD,CAApB;AACH,KAFD;AAIH,GA9BQ,EA8BN,CAACV,eAAD,CA9BM,CAAT;AAgCA,sBACI;AAAA,4BACI,QAAC,kBAAD;AAAoB,MAAA,SAAS,EAAEC;AAA/B;AAAA;AAAA;AAAA;AAAA,YADJ,eAEI,QAAC,mBAAD;AAAqB,MAAA,SAAS,EAAEA,SAAhC;AAA2C,MAAA,QAAQ,EAAEO;AAArD;AAAA;AAAA;AAAA;AAAA,YAFJ;AAAA;AAAA;AAAA;AAAA;AAAA,UADJ;AAQH,CAhDA;;GAAMT,gB;;KAAAA,gB;AAkDP,eAAeA,gBAAf","sourcesContent":["import React, {useEffect, useState} from 'react'\nimport WaveformVisualiser from '../Visualisers/WaveformVisualiser'\nimport FrequencyVisualiser from '../Visualisers/FrequencyVisualiser'\n\n\n const MicAudioAnalyser = ({ microphoneInput }) => {\n\n    const [audioData, setAudioData] = useState(new Uint8Array(0));\n    // creates an audio context\n    const audioContext = new (window.AudioContext || window.webkitAudioContext)();\n    // creates analyser node\n    const analyser = audioContext.createAnalyser();\n    \n    useEffect( () => {\n        // empty request animation frame Id\n        let rafId;\n        \n        \n        \n        // Creates a data Array which is half the length of the fftSize\n        // it takes in unsigned integers  \n        const dataArray = new Uint8Array(analyser.frequencyBinCount);\n        \n        // creates a source variable containing the media stream source\n        const source = audioContext.createMediaStreamSource(microphoneInput)\n        // connects the audio stream to the analyser node\n        source.connect(analyser)\n        const tick = () => {\n            // copies wave form data into the dataArray which is passed in as an argument   \n            analyser.getByteTimeDomainData(dataArray)\n            // sets audioData to be the value of a copy of dataArray\n            console.log(\"audio data:\",dataArray)\n            setAudioData([...dataArray])\n            // requests a re-render while calling tick in a recursive loop\n            rafId = requestAnimationFrame(tick);\n        }\n    \n        rafId = requestAnimationFrame(tick);\n\n        return function cleanup() {\n            cancelAnimationFrame(rafId);\n        }\n\n    }, [microphoneInput])\n\n    return(\n        <div>\n            <WaveformVisualiser audioData={audioData}/>\n            <FrequencyVisualiser audioData={audioData} analyser={analyser}/> \n        </div>\n        \n    )\n\n}\n\nexport default MicAudioAnalyser;"]},"metadata":{},"sourceType":"module"}